{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Avance del proyecto\n",
    "### Detección de Automobiles Mediante AUV Basado en Transfer learning\n",
    "### Reconocimiento de X & y "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "yNj4DVaaYWWf"
   },
   "outputs": [],
   "source": [
    "'''Librerias'''\n",
    "import h5py\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, make_scorer\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "import keras\n",
    "from keras.datasets import cifar10\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.utils import np_utils\n",
    "from keras.layers import Dense, Activation, Flatten, Dropout, BatchNormalization,Conv2D,MaxPooling2D\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras import regularizers, optimizers\n",
    "from keras.regularizers import l2\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Testeo de datos'''\n",
    "test_size    = 0.20\n",
    "seed         = 6\n",
    "h5_color     = 'C:/Users/Junior/Desktop/Proyecto mineria/Features_Data/color_features.h5'\n",
    "h5_colorLb   = 'C:/Users/Junior/Desktop/Proyecto mineria/Features_Data/color_features_labels.h5'\n",
    "h5_texture   = 'C:/Users/Junior/Desktop/Proyecto mineria/Features_Data/textural_features.h5'\n",
    "h5_textureLb = 'C:/Users/Junior/Desktop/Proyecto mineria/Features_Data/textural_features_labels.h5'\n",
    "scoring      = {'accuracy' : make_scorer(accuracy_score),\n",
    "                'f1_score' : make_scorer(f1_score, average = 'weighted'), \n",
    "                'precision' : make_scorer(precision_score, average = 'weighted'),\n",
    "                'recall' : make_scorer(recall_score, average = 'weighted')}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[STATUS] features shape: (2400, 4512)\n",
      "[STATUS] labels shape: (400, 512)\n",
      "[STATUS] training started...\n"
     ]
    }
   ],
   "source": [
    "'''Normalización'''\n",
    "\n",
    "'''importar el vector de características y las etiquetas entrenadas'''\n",
    "\n",
    "h5f_color   = h5py.File(h5_color, 'r')\n",
    "h5f_colorLb = h5py.File(h5_colorLb, 'r')\n",
    "\n",
    "color_features_string          = h5f_color['Vehicle_Color_Features']\n",
    "color_features_labels_string   = h5f_colorLb['Vehicle_Color_Features_Labels']\n",
    "\n",
    "color_features = np.array(color_features_string)\n",
    "color_features_labels  = np.array(color_features_labels_string)\n",
    "\n",
    "h5f_color.close()\n",
    "h5f_colorLb.close()\n",
    "\n",
    "'''verificar la forma del vector de características y las etiquetas'''\n",
    "\n",
    "print(\"[STATUS] features shape: {}\".format(color_features.shape))\n",
    "print(\"[STATUS] labels shape: {}\".format(color_features_labels.shape))\n",
    "print(\"[STATUS] training started...\")\n",
    "\n",
    "'''Dividir X & y'''\n",
    "x = global_features\n",
    "Y = color_features_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Dividir X & y'''\n",
    "x = global_features\n",
    "Y = color_features_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MobileNetV2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Librerias para MobileNet'''\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.applications import MobileNetV2\n",
    "from keras.layers import AveragePooling2D\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Input\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from keras.preprocessing.image import load_img\n",
    "from keras.utils import to_categorical\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from keras.models import model_from_json\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import glob\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "z3lQnlfjeVvT",
    "outputId": "ee83bda3-0fd0-47b1-c8be-cbd8a1b74a53"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train = (4500, 32, 32, 3)\n",
      "x_valid = (4500, 32, 32, 3)\n",
      "x_test = (4500, 32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "'''Definicion de '''\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, Y,\n",
    "                                        test_size   = test_size,\n",
    "                                        random_state = seed)\n",
    "\n",
    "x_train.shape,x_test.shape\n",
    "\n",
    "(x_train, x_valid) = x_train[2000:], x_train[:2000]\n",
    "(y_train, y_valid) = y_train[2000:], y_train[:2000]\n",
    "\n",
    "#print the shape of x_train, x_valid, and x_test\n",
    "\n",
    "print('x_train =', x_train.shape)\n",
    "print('x_valid =', x_train.shape)\n",
    "print('x_test =', x_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wQ7p-aCrLepu",
    "outputId": "4d3dc3af-cbd0-4d95-e546-24114070a83e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Find 5.567 images with 3 classes\n"
     ]
    }
   ],
   "source": [
    "'''Verificación datos de entrada y etiquetas correspondientes'''\n",
    "for image_path in dataset_paths:\n",
    "  label = image_path.split(os.path.sep)[-2]\n",
    "  image=load_img(image_path,target_size=(80,80))\n",
    "  image=img_to_array(image)\n",
    "\n",
    "'''Impresión de datos'''\n",
    "print(\"[INFO] Find {:d} images with {:d} classes\".format(len(X),len(set(labels))))\n",
    "\n",
    "'''guardar el archivo de etiqueta para que podamos usarlo en otro script'''\n",
    "np.save('license_character_classes.npy', lb.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Iqt_RqP0Lep0"
   },
   "outputs": [],
   "source": [
    "'''Definir modelo básico'''\n",
    "def create_model(lr=1e-4,decay=1e-4/25, training=False,output_shape=y.shape[1]):\n",
    "    #Determinar modelo MobileNet\n",
    "    baseModel = MobileNetV2(weights=\"imagenet\", \n",
    "                            include_top=False,\n",
    "                            input_tensor=Input(shape=(80, 80, 3)))\n",
    "    #Caraterización del modelo y capas\n",
    "    headModel = baseModel.output\n",
    "    headModel = AveragePooling2D(pool_size=(3, 3))(headModel)\n",
    "    headModel = Flatten(name=\"flatten\")(headModel)\n",
    "    headModel = Dense(128, activation=\"relu\")(headModel)\n",
    "    headModel = Dropout(0.5)(headModel)\n",
    "    headModel = Dense(output_shape, activation=\"softmax\")(headModel)\n",
    "    '''Defición final del modelo'''\n",
    "    model = Model(inputs=baseModel.input, outputs=headModel)\n",
    "    \n",
    "    if training:\n",
    "        # definir capa entrenable\n",
    "        for layer in baseModel.layers:\n",
    "            layer.trainable = True\n",
    "        # Compilar modelo\n",
    "        optimizer = Adam(lr=lr, decay = decay)\n",
    "        model.compile(loss=\"categorical_crossentropy\", optimizer=optimizer,metrics=[\"accuracy\"])    \n",
    "        \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 87
    },
    "id": "re5ESp6eLep2",
    "outputId": "1ee65f8d-d422-4c46-a3b0-d32f1d5b94fb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224_no_top.h5\n",
      "9412608/9406464 [==============================] - 0s 0us/step\n"
     ]
    }
   ],
   "source": [
    "'''Inicializar el hiperparámetro inicial'''\n",
    "INIT_LR = 1e-4\n",
    "'''Vueltas'''\n",
    "EPOCHS = 30\n",
    "'''Definición de modelo'''\n",
    "model = create_model(lr=INIT_LR, decay=INIT_LR/EPOCHS,training=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "vhhqQuQCLep5",
    "outputId": "6abb9a46-43b4-4f6d-ac34-3b073c4c9cde"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "12/12 [==============================] - ETA: 0s - loss: 1.3502 - accuracy: 0.6237\n",
      "Epoch 00001: saving model to License_character_recognition.h5\n",
      "12/12 [==============================] - 2s 180ms/step - loss: 1.3502 - accuracy: 0.6237 - val_loss: 3.4287 - val_accuracy: 0.3478\n",
      "Epoch 2/30\n",
      "12/12 [==============================] - ETA: 0s - loss: 1.2676 - accuracy: 0.6575\n",
      "Epoch 00002: saving model to License_character_recognition.h5\n",
      "12/12 [==============================] - 2s 184ms/step - loss: 1.2676 - accuracy: 0.6575 - val_loss: 2.9684 - val_accuracy: 0.3478\n",
      "Epoch 3/30\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.9559 - accuracy: 0.7244\n",
      "Epoch 00003: saving model to License_character_recognition.h5\n",
      "12/12 [==============================] - 2s 145ms/step - loss: 0.9559 - accuracy: 0.7244 - val_loss: 2.8284 - val_accuracy: 0.3913\n",
      "Epoch 4/30\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.8010 - accuracy: 0.7769\n",
      "Epoch 00004: saving model to License_character_recognition.h5\n",
      "12/12 [==============================] - 2s 148ms/step - loss: 0.8010 - accuracy: 0.7769 - val_loss: 2.7580 - val_accuracy: 0.4022\n",
      "Epoch 5/30\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.6761 - accuracy: 0.8189\n",
      "Epoch 00005: saving model to License_character_recognition.h5\n",
      "12/12 [==============================] - 2s 163ms/step - loss: 0.6761 - accuracy: 0.8189 - val_loss: 2.6058 - val_accuracy: 0.4130\n",
      "Epoch 6/30\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.5372 - accuracy: 0.8398\n",
      "Epoch 00006: saving model to License_character_recognition.h5\n",
      "12/12 [==============================] - 2s 154ms/step - loss: 0.5372 - accuracy: 0.8398 - val_loss: 2.5434 - val_accuracy: 0.4457\n",
      "Epoch 7/30\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.5027 - accuracy: 0.8609\n",
      "Epoch 00007: saving model to License_character_recognition.h5\n",
      "12/12 [==============================] - 2s 148ms/step - loss: 0.5027 - accuracy: 0.8609 - val_loss: 2.3985 - val_accuracy: 0.4565\n",
      "Epoch 8/30\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.4467 - accuracy: 0.8714\n",
      "Epoch 00008: saving model to License_character_recognition.h5\n",
      "12/12 [==============================] - 2s 149ms/step - loss: 0.4467 - accuracy: 0.8714 - val_loss: 2.1688 - val_accuracy: 0.4674\n",
      "Epoch 9/30\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.3890 - accuracy: 0.8885\n",
      "Epoch 00009: saving model to License_character_recognition.h5\n",
      "12/12 [==============================] - 2s 148ms/step - loss: 0.3890 - accuracy: 0.8885 - val_loss: 2.0771 - val_accuracy: 0.5326\n",
      "Epoch 10/30\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.3355 - accuracy: 0.9094\n",
      "Epoch 00010: saving model to License_character_recognition.h5\n",
      "12/12 [==============================] - 2s 150ms/step - loss: 0.3355 - accuracy: 0.9094 - val_loss: 2.0577 - val_accuracy: 0.5435\n",
      "Epoch 11/30\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.3106 - accuracy: 0.9173\n",
      "Epoch 00011: saving model to License_character_recognition.h5\n",
      "12/12 [==============================] - 2s 152ms/step - loss: 0.3106 - accuracy: 0.9173 - val_loss: 2.0330 - val_accuracy: 0.5435\n",
      "Epoch 12/30\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.2944 - accuracy: 0.9213\n",
      "Epoch 00012: saving model to License_character_recognition.h5\n",
      "12/12 [==============================] - 2s 150ms/step - loss: 0.2944 - accuracy: 0.9213 - val_loss: 1.8810 - val_accuracy: 0.5543\n",
      "Epoch 13/30\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.2761 - accuracy: 0.9278\n",
      "Epoch 00013: saving model to License_character_recognition.h5\n",
      "12/12 [==============================] - 2s 150ms/step - loss: 0.2761 - accuracy: 0.9278 - val_loss: 1.8563 - val_accuracy: 0.5761\n",
      "Epoch 14/30\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.2675 - accuracy: 0.9344\n",
      "Epoch 00014: saving model to License_character_recognition.h5\n",
      "12/12 [==============================] - 2s 151ms/step - loss: 0.2675 - accuracy: 0.9344 - val_loss: 1.7981 - val_accuracy: 0.5978\n",
      "Epoch 15/30\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.2722 - accuracy: 0.9344\n",
      "Epoch 00015: saving model to License_character_recognition.h5\n",
      "12/12 [==============================] - 2s 148ms/step - loss: 0.2722 - accuracy: 0.9344 - val_loss: 1.7693 - val_accuracy: 0.6196\n",
      "Epoch 16/30\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.2062 - accuracy: 0.9475\n",
      "Epoch 00016: saving model to License_character_recognition.h5\n",
      "12/12 [==============================] - 2s 150ms/step - loss: 0.2062 - accuracy: 0.9475 - val_loss: 1.7353 - val_accuracy: 0.6630\n",
      "Epoch 17/30\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.2080 - accuracy: 0.9488\n",
      "Epoch 00017: saving model to License_character_recognition.h5\n",
      "12/12 [==============================] - 2s 150ms/step - loss: 0.2080 - accuracy: 0.9488 - val_loss: 1.6851 - val_accuracy: 0.6522\n",
      "Epoch 18/30\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.1725 - accuracy: 0.9554\n",
      "Epoch 00018: saving model to License_character_recognition.h5\n",
      "12/12 [==============================] - 2s 147ms/step - loss: 0.1725 - accuracy: 0.9554 - val_loss: 1.6936 - val_accuracy: 0.6522\n",
      "Epoch 19/30\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.1840 - accuracy: 0.9475\n",
      "Epoch 00019: saving model to License_character_recognition.h5\n",
      "12/12 [==============================] - 2s 147ms/step - loss: 0.1840 - accuracy: 0.9475 - val_loss: 1.7191 - val_accuracy: 0.5870\n",
      "Epoch 20/30\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.1502 - accuracy: 0.9619\n",
      "Epoch 00020: saving model to License_character_recognition.h5\n",
      "12/12 [==============================] - 2s 153ms/step - loss: 0.1502 - accuracy: 0.9619 - val_loss: 1.7137 - val_accuracy: 0.5978\n",
      "Epoch 21/30\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.1353 - accuracy: 0.9685\n",
      "Epoch 00021: saving model to License_character_recognition.h5\n",
      "12/12 [==============================] - 2s 159ms/step - loss: 0.1353 - accuracy: 0.9685 - val_loss: 1.6837 - val_accuracy: 0.6522\n",
      "Epoch 22/30\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.1376 - accuracy: 0.9674\n",
      "Epoch 00022: saving model to License_character_recognition.h5\n",
      "12/12 [==============================] - 2s 160ms/step - loss: 0.1376 - accuracy: 0.9674 - val_loss: 1.6503 - val_accuracy: 0.6196\n",
      "Epoch 23/30\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.1266 - accuracy: 0.9606\n",
      "Epoch 00023: saving model to License_character_recognition.h5\n",
      "12/12 [==============================] - 2s 157ms/step - loss: 0.1266 - accuracy: 0.9606 - val_loss: 1.6550 - val_accuracy: 0.6413\n",
      "Epoch 24/30\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.1081 - accuracy: 0.9751\n",
      "Epoch 00024: saving model to License_character_recognition.h5\n",
      "12/12 [==============================] - 2s 157ms/step - loss: 0.1081 - accuracy: 0.9751 - val_loss: 1.6391 - val_accuracy: 0.6304\n",
      "Epoch 25/30\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.1402 - accuracy: 0.9606\n",
      "Epoch 00025: saving model to License_character_recognition.h5\n",
      "12/12 [==============================] - 2s 152ms/step - loss: 0.1402 - accuracy: 0.9606 - val_loss: 1.6007 - val_accuracy: 0.6304\n",
      "Epoch 26/30\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.1265 - accuracy: 0.9659\n",
      "Epoch 00026: saving model to License_character_recognition.h5\n",
      "12/12 [==============================] - 2s 151ms/step - loss: 0.1265 - accuracy: 0.9659 - val_loss: 1.5976 - val_accuracy: 0.6413\n",
      "Epoch 27/30\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.1321 - accuracy: 0.9619\n",
      "Epoch 00027: saving model to License_character_recognition.h5\n",
      "12/12 [==============================] - 2s 151ms/step - loss: 0.1321 - accuracy: 0.9619 - val_loss: 1.5769 - val_accuracy: 0.6848\n",
      "Epoch 28/30\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.1094 - accuracy: 0.9688\n",
      "Epoch 00028: saving model to License_character_recognition.h5\n",
      "12/12 [==============================] - 2s 151ms/step - loss: 0.1094 - accuracy: 0.9688 - val_loss: 1.5373 - val_accuracy: 0.6848\n",
      "Epoch 29/30\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.1034 - accuracy: 0.9724\n",
      "Epoch 00029: saving model to License_character_recognition.h5\n",
      "12/12 [==============================] - 2s 154ms/step - loss: 0.1034 - accuracy: 0.9724 - val_loss: 1.4762 - val_accuracy: 0.6739\n",
      "Epoch 30/30\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.1181 - accuracy: 0.9711\n",
      "Epoch 00030: saving model to License_character_recognition.h5\n",
      "12/12 [==============================] - 2s 151ms/step - loss: 0.1181 - accuracy: 0.9711 - val_loss: 1.4245 - val_accuracy: 0.6739\n"
     ]
    }
   ],
   "source": [
    "'''Definir peso'''\n",
    "BATCH_SIZE = 64\n",
    "'''Definición de modelo'''\n",
    "my_checkpointer = [\n",
    "                EarlyStopping(monitor='val_loss', patience=5, verbose=1),\n",
    "                ModelCheckpoint(filepath=\"Vehicle_Color_Features_Labels.h5\", verbose=1, save_weights_only=True)\n",
    "                ]\n",
    "#Impresión de resultados\n",
    "result = model.fit_generator(image_gen.flow(trainX, trainY, batch_size=64), \n",
    "                   steps_per_epoch=len(trainX) // BATCH_SIZE, \n",
    "                   validation_data=(testX, testY), \n",
    "                   validation_steps=len(testX) // BATCH_SIZE, \n",
    "                   epochs=EPOCHS, callbacks=my_checkpointer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "F7O17Ecj1sF7",
    "outputId": "0c55ffa1-5cee-4235-96aa-546dc2b11442"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 92.20\n",
      "F1 score: 80.12\n",
      "Recall: 91.14\n"
     ]
    }
   ],
   "source": [
    "'''Evaluar el modelo'''\n",
    "\n",
    "'''Para evaluar el modelo, usamos una función de Keras llamada *evaluar* e imprimimos los resultados'''\n",
    "model_probs = model.predict(test_ds, verbose=0)\n",
    "# predict crisp classes for test set\n",
    "model_classes = np.argmax(model_probs,axis=1)\n",
    "# reduce to 1d array\n",
    "model_probs = model_probs[:, 0]\n",
    " \n",
    "\n",
    "# accuracy: (tp + tn) / (p + n)\n",
    "accuracy = accuracy_score(test_labels, model_classes)*100\n",
    "# f1: 2 tp / (2 tp + fp + fn)\n",
    "f1 = f1_score(test_labels, model_classes, average='weighted')*100\n",
    "# recall: tp / (tp + fn)\n",
    "recall = recall_score(test_labels, model_classes, average='weighted')*100\n",
    "\n",
    "\n",
    "print('Accuracy: %.2f' % accuracy)\n",
    "print('F1 score: %.2f' % f1)\n",
    "print('Recall: %.2f' % recall)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyPreavICEbpxzdMEd2S2sqf",
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "AlexNet implementation",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "f5b39627973f3d41197536d1010f9865eb97092b257fe4cc48fe612ffbfa825a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
